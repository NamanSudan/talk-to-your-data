VLLM_CONFIG = {
    "endpoint": "http://0.0.0.0:8000",
    "max_tokens": 512,
    "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
    "enable_lora": True
}
